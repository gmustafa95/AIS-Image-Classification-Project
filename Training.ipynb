{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Trainingipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP9R8FvHSZLVjozVs+E1Ase"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"iFDeUwrK0LBZ"},"source":["!git clone https://github.com/matterport/Mask_RCNN.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xyT02kne0NPy"},"source":["!pip install keras==2.2.5\n","!pip install tensorflow==1.15"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U6pp1MZa0QR-"},"source":["import os\n","os.chdir(\"Mask_RCNN/samples\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ktT9-iMa0SaY"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tasw_IoY0VqN"},"source":["import os\n","import sys\n","import json\n","import datetime\n","import numpy as np\n","import skimage.draw\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","# Root directory of the project\n","#ROOT_DIR = os.path.abspath(\"C:/MaskRCNN-main/main/Mask_RCNN\")\n","ROOT_DIR = os.path.abspath(\"../\")\n","\n","# Import Mask RCNN\n","sys.path.append(ROOT_DIR)  # To find local version of the library\n","from mrcnn.visualize import display_instances\n","from mrcnn.config import Config\n","from mrcnn import model as modellib, utils\n","\n","# Path to trained weights file\n","COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"/content/drive/MyDrive/mask_rcnn_coco.h5\")\n","\n","# Directory to save logs and model checkpoints, if not provided\n","# through the command line argument --logs\n","DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EbWjITbV0X01"},"source":["class CustomConfig(Config):\n","    \"\"\"Configuration for training on the toy  dataset.\n","    Derives from the base Config class and overrides some values.\n","    \"\"\"\n","    # Give the configuration a recognizable name\n","    NAME = \"object\"\n","\n","    # We use a GPU with 12GB memory, which can fit two images.\n","    # Adjust down if you use a smaller GPU.\n","    IMAGES_PER_GPU = 2\n","\n","    # Number of classes (including background)\n","    NUM_CLASSES = 1 + 10  # Background + Number of Classes\n","\n","    # Number of training steps per epoch\n","    STEPS_PER_EPOCH = 100\n","\n","    # Skip detections with < 90% confidence\n","    DETECTION_MIN_CONFIDENCE = 0.9"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NmWK35aQ0ch9"},"source":["class CustomDataset(utils.Dataset):\n","\n","    def load_custom(self, dataset_dir, subset):\n","\n","        # Add classes. We have only one class to add.\n","        self.add_class(\"object\", 1, \"window\")\n","        self.add_class(\"object\", 2, \"table\")\n","        self.add_class(\"object\", 3, \"chair\")\n","        self.add_class(\"object\", 4, \"door\")\n","        self.add_class(\"object\", 5, \"smartphone\")\n","        self.add_class(\"object\", 6, \"bed\")\n","        self.add_class(\"object\", 7, \"laptop\")\n","        self.add_class(\"object\", 8, \"keyboard\")\n","        self.add_class(\"object\", 9, \"computer mouse\")\n","        self.add_class(\"object\", 10, \"monitor\")\n","\n","\n","        #self.add_class(\"object\", 8, \"bottle \")\n","        #self.add_class(\"object\", 9, \"table Lamp\")\n","        #self.add_class(\"object\", 10, \"washing machine\")\n","        #self.add_class(\"object\", 11, \"fan\")\n","        #self.add_class(\"object\", 13, \"dustbin\")\n","        #self.add_class(\"object\", 14, \"vaccum cleaner\")\n","        #self.add_class(\"object\", 15, \"cleaning mop\")\n","        #self.add_class(\"object\", 16, \"coffee cup\")\n","        #self.add_class(\"object\", 17, \"cupboard\")\n","        # self.add_class(\"object\", 3, \"xyz\")\n","\n","        # Train or validation dataset?\n","        assert subset in [\"train\", \"val\"]\n","        dataset_dir = os.path.join(dataset_dir, subset)\n","\n","        # Load annotations\n","        # VGG Image Annotator saves each image in the form:\n","        # { 'filename': '28503151_5b5b7ec140_b.jpg',\n","        #   'regions': {\n","        #       '0': {\n","        #           'region_attributes': {},\n","        #           'shape_attributes': {\n","        #               'all_points_x': [...],\n","        #               'all_points_y': [...],\n","        #               'name': 'polygon'}},\n","        #       ... more regions ...\n","        #   },\n","        #   'size': 100202\n","        # }\n","        # We mostly care about the x and y coordinates of each region\n","        annotations1 = json.load(open(os.path.join(dataset_dir, \"AIS_Dataset.json\")))\n","        # print(annotations1)\n","        annotations = list(annotations1.values())  # don't need the dict keys\n","\n","        # The VIA tool saves images in the JSON even if they don't have any\n","        # annotations. Skip unannotated images.\n","        annotations = [a for a in annotations if a['regions']]\n","        \n","        # Add images\n","        for a in annotations:\n","            # print(a)\n","            # Get the x, y coordinaets of points of the polygons that make up\n","            # the outline of each object instance. There are stores in the\n","            # shape_attributes (see json format above)\n","            polygons = [r['shape_attributes'] for r in a['regions']] \n","            objects = [s['region_attributes']['name'] for s in a['regions']]\n","            print(\"objects:\",objects)\n","            name_dict = {\"window\": 1,\n","                         \"table\": 2,\n","                         \"chair\": 3,\n","                         \"door\": 4,\n","                         \"smartphone\": 5,\n","                         \"bed\": 6,\n","                         \"laptop\": 7,\n","                         \"keyboard\": 8,\n","                         \"computer mouse\": 9,\n","                         \"monitor\": 10}\n","      \n","            # key = tuple(name_dict)\n","            num_ids = [name_dict[a] for a in objects]\n","     \n","            # num_ids = [int(n['Event']) for n in objects]\n","            # load_mask() needs the image size to convert polygons to masks.\n","            # Unfortunately, VIA doesn't include it in JSON, so we must read\n","            # the image. This is only managable since the dataset is tiny.\n","            print(\"numids\",num_ids)\n","            image_path = os.path.join(dataset_dir, a['filename'])\n","            image = skimage.io.imread(image_path)\n","            height, width = image.shape[:2]\n","\n","            self.add_image(\n","                \"object\",  ## for a single class just add the name here\n","                image_id=a['filename'],  # use file name as a unique image id\n","                path=image_path,\n","                width=width, height=height,\n","                polygons=polygons,\n","                num_ids=num_ids\n","                )\n","\n","    def load_mask(self, image_id):\n","        \"\"\"Generate instance masks for an image.\n","       Returns:\n","        masks: A bool array of shape [height, width, instance count] with\n","            one mask per instance.\n","        class_ids: a 1D array of class IDs of the instance masks.\n","        \"\"\"\n","        # If not a Dog-Cat dataset image, delegate to parent class.\n","        image_info = self.image_info[image_id]\n","        if image_info[\"source\"] != \"object\":\n","            return super(self.__class__, self).load_mask(image_id)\n","\n","        # Convert polygons to a bitmap mask of shape\n","        # [height, width, instance_count]\n","        info = self.image_info[image_id]\n","        if info[\"source\"] != \"object\":\n","            return super(self.__class__, self).load_mask(image_id)\n","        num_ids = info['num_ids']\n","        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n","                        dtype=np.uint8)\n","        for i, p in enumerate(info[\"polygons\"]):\n","            # Get indexes of pixels inside the polygon and set them to 1\n","        \trr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n","\n","        \tmask[rr, cc, i] = 1\n","\n","        # Return mask, and array of class IDs of each instance. Since we have\n","        # one class ID only, we return an array of 1s\n","        # Map class names to class IDs.\n","        num_ids = np.array(num_ids, dtype=np.int32)\n","        return mask, num_ids #np.ones([mask.shape[-1]], dtype=np.int32)\n","\n","    def image_reference(self, image_id):\n","        \"\"\"Return the path of the image.\"\"\"\n","        info = self.image_info[image_id]\n","        if info[\"source\"] == \"object\":\n","            return info[\"path\"]\n","        else:\n","            super(self.__class__, self).image_reference(image_id)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ezxNBH7w0drP"},"source":["def train(model):\n","    \"\"\"Train the model.\"\"\"\n","    # Training dataset.\n","    dataset_train = CustomDataset()\n","    dataset_train.load_custom(\"/content/drive/MyDrive\", \"train\")\n","    dataset_train.prepare()\n","\n","    # Validation dataset\n","    dataset_val = CustomDataset()\n","    dataset_val.load_custom(\"/content/drive/MyDrive\", \"val\")\n","    dataset_val.prepare()\n","\n","    # *** This training schedule is an example. Update to your needs ***\n","    # Since we're using a very small dataset, and starting from\n","    # COCO trained weights, we don't need to train too long. Also,\n","    # no need to train all layers, just the heads should do it.\n","    print(\"Training network heads\")\n","    model.train(dataset_train, dataset_val,\n","                learning_rate=config.LEARNING_RATE,\n","                epochs=100,\n","                layers='heads')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WWkHfghz0gOv"},"source":["config = CustomConfig()\n","model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=DEFAULT_LOGS_DIR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z1lKhpit0jdO"},"source":["weights_path = COCO_WEIGHTS_PATH\n","        # Download weights file\n","if not os.path.exists(weights_path):\n","  utils.download_trained_weights(weights_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4v0v1jfv0mF-"},"source":["model.load_weights(weights_path, by_name=True, exclude=[\n","            \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n","            \"mrcnn_bbox\", \"mrcnn_mask\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ruITW2eH0qeG"},"source":["#!pip install keras==2.2.5\n","# if error occurs restart runtime\n","train(model)"],"execution_count":null,"outputs":[]}]}